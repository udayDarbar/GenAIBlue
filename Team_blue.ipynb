{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93ebd047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.7.1-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting bigvgan\n",
      "  Using cached bigvgan-2.4.1-py3-none-any.whl.metadata (430 bytes)\n",
      "Requirement already satisfied: sounddevice in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.5.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.5.1)\n",
      "Requirement already satisfied: torch==2.7.1 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchaudio) (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.7.1->torchaudio) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.7.1->torchaudio) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.7.1->torchaudio) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.7.1->torchaudio) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.7.1->torchaudio) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.7.1->torchaudio) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch==2.7.1->torchaudio) (80.9.0)\n",
      "Collecting auraloss (from bigvgan)\n",
      "  Using cached auraloss-0.4.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.4 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from bigvgan) (0.33.4)\n",
      "Collecting librosa>=0.8.1 (from bigvgan)\n",
      "  Using cached librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from bigvgan) (3.10.3)\n",
      "Collecting ninja (from bigvgan)\n",
      "  Using cached ninja-1.11.1.4-py3-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting nnaudio (from bigvgan)\n",
      "  Using cached nnAudio-0.3.3-py3-none-any.whl.metadata (771 bytes)\n",
      "Requirement already satisfied: numpy in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from bigvgan) (1.26.4)\n",
      "Collecting pesq (from bigvgan)\n",
      "  Using cached pesq-0.0.4.tar.gz (38 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scipy in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from bigvgan) (1.15.3)\n",
      "Collecting soundfile (from bigvgan)\n",
      "  Using cached soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from bigvgan) (2.19.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from bigvgan) (4.67.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sounddevice) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from CFFI>=1.0->sounddevice) (2.22)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub>=0.23.4->bigvgan) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub>=0.23.4->bigvgan) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub>=0.23.4->bigvgan) (2.32.4)\n",
      "Collecting audioread>=2.1.9 (from librosa>=0.8.1->bigvgan)\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from librosa>=0.8.1->bigvgan) (0.61.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from librosa>=0.8.1->bigvgan) (1.7.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from librosa>=0.8.1->bigvgan) (5.2.1)\n",
      "Collecting pooch>=1.1 (from librosa>=0.8.1->bigvgan)\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa>=0.8.1->bigvgan)\n",
      "  Using cached soxr-0.5.0.post1-cp312-abi3-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from librosa>=0.8.1->bigvgan) (0.4)\n",
      "Collecting msgpack>=1.0 (from librosa>=0.8.1->bigvgan)\n",
      "  Using cached msgpack-1.1.1-cp312-cp312-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from numba>=0.51.0->librosa>=0.8.1->bigvgan) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pooch>=1.1->librosa>=0.8.1->bigvgan) (4.3.8)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->huggingface-hub>=0.23.4->bigvgan) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->huggingface-hub>=0.23.4->bigvgan) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->huggingface-hub>=0.23.4->bigvgan) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->huggingface-hub>=0.23.4->bigvgan) (2025.4.26)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-learn>=1.1.0->librosa>=0.8.1->bigvgan) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy>=1.13.3->torch==2.7.1->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm->bigvgan) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch==2.7.1->torchaudio) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->bigvgan) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->bigvgan) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->bigvgan) (4.58.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->bigvgan) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->bigvgan) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->bigvgan) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->bigvgan) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.7->matplotlib->bigvgan) (1.17.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard->bigvgan) (2.3.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard->bigvgan) (1.73.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard->bigvgan) (3.8)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard->bigvgan) (4.25.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard->bigvgan) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard->bigvgan) (3.1.3)\n",
      "Using cached torchaudio-2.7.1-cp312-cp312-win_amd64.whl (2.5 MB)\n",
      "Using cached bigvgan-2.4.1-py3-none-any.whl (40 kB)\n",
      "Using cached librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Using cached msgpack-1.1.1-cp312-cp312-win_amd64.whl (72 kB)\n",
      "Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Using cached soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "Using cached soxr-0.5.0.post1-cp312-abi3-win_amd64.whl (164 kB)\n",
      "Using cached auraloss-0.4.0-py3-none-any.whl (16 kB)\n",
      "Using cached ninja-1.11.1.4-py3-none-win_amd64.whl (296 kB)\n",
      "Using cached nnAudio-0.3.3-py3-none-any.whl (43 kB)\n",
      "Building wheels for collected packages: pesq\n",
      "  Building wheel for pesq (setup.py): started\n",
      "  Building wheel for pesq (setup.py): finished with status 'done'\n",
      "  Created wheel for pesq: filename=pesq-0.0.4-cp312-cp312-win_amd64.whl size=116474 sha256=8f61f7327aac7a9329710e1504ce5f5bea576df8d28d918346667f13d6b96769\n",
      "  Stored in directory: c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local\\pip\\cache\\wheels\\9b\\d4\\a4\\9cf3512534cd47ce4a036d1593ee4013f2bf7509e631a147a3\n",
      "Successfully built pesq\n",
      "Installing collected packages: pesq, soxr, ninja, msgpack, audioread, soundfile, pooch, torchaudio, nnaudio, librosa, auraloss, bigvgan\n",
      "\n",
      "   ------ ---------------------------------  2/12 [ninja]\n",
      "   ---------- -----------------------------  3/12 [msgpack]\n",
      "   ------------- --------------------------  4/12 [audioread]\n",
      "   ---------------- -----------------------  5/12 [soundfile]\n",
      "   -------------------- -------------------  6/12 [pooch]\n",
      "   -------------------- -------------------  6/12 [pooch]\n",
      "   ----------------------- ----------------  7/12 [torchaudio]\n",
      "   ----------------------- ----------------  7/12 [torchaudio]\n",
      "   ----------------------- ----------------  7/12 [torchaudio]\n",
      "   ----------------------- ----------------  7/12 [torchaudio]\n",
      "   ----------------------- ----------------  7/12 [torchaudio]\n",
      "   ----------------------- ----------------  7/12 [torchaudio]\n",
      "   ----------------------- ----------------  7/12 [torchaudio]\n",
      "   ----------------------- ----------------  7/12 [torchaudio]\n",
      "   ----------------------- ----------------  7/12 [torchaudio]\n",
      "   ----------------------- ----------------  7/12 [torchaudio]\n",
      "   ----------------------- ----------------  7/12 [torchaudio]\n",
      "   ----------------------- ----------------  7/12 [torchaudio]\n",
      "   ----------------------- ----------------  7/12 [torchaudio]\n",
      "   ----------------------- ----------------  7/12 [torchaudio]\n",
      "   ----------------------- ----------------  7/12 [torchaudio]\n",
      "   ----------------------- ----------------  7/12 [torchaudio]\n",
      "   ----------------------- ----------------  7/12 [torchaudio]\n",
      "   ----------------------- ----------------  7/12 [torchaudio]\n",
      "   -------------------------- -------------  8/12 [nnaudio]\n",
      "   ------------------------------ ---------  9/12 [librosa]\n",
      "   ------------------------------ ---------  9/12 [librosa]\n",
      "   ------------------------------ ---------  9/12 [librosa]\n",
      "   ------------------------------ ---------  9/12 [librosa]\n",
      "   ------------------------------ ---------  9/12 [librosa]\n",
      "   ------------------------------ ---------  9/12 [librosa]\n",
      "   --------------------------------- ------ 10/12 [auraloss]\n",
      "   ------------------------------------ --- 11/12 [bigvgan]\n",
      "   ------------------------------------ --- 11/12 [bigvgan]\n",
      "   ------------------------------------ --- 11/12 [bigvgan]\n",
      "   ---------------------------------------- 12/12 [bigvgan]\n",
      "\n",
      "Successfully installed audioread-3.0.1 auraloss-0.4.0 bigvgan-2.4.1 librosa-0.11.0 msgpack-1.1.1 ninja-1.11.1.4 nnaudio-0.3.3 pesq-0.0.4 pooch-1.8.2 soundfile-0.13.1 soxr-0.5.0.post1 torchaudio-2.7.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'pesq' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pesq'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "!pip install torchaudio bigvgan sounddevice joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24d68e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.3.14.tar.gz (51.0 MB)\n",
      "     ---------------------------------------- 0.0/51.0 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 3.4/51.0 MB 28.6 MB/s eta 0:00:02\n",
      "     ------------ -------------------------- 16.3/51.0 MB 44.4 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 37.2/51.0 MB 65.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  50.9/51.0 MB 72.0 MB/s eta 0:00:01\n",
      "     --------------------------------------- 51.0/51.0 MB 64.9 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-cpp-python) (4.14.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-cpp-python) (1.26.4)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-cpp-python) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): started\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): still running...\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): still running...\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.14-cp312-cp312-win_amd64.whl size=4081706 sha256=04a21efa836088c564842038fb0e90a905239b0735faace43e86113501411ea4\n",
      "  Stored in directory: c:\\users\\udayr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local\\pip\\cache\\wheels\\c5\\9e\\01\\05936741e29a5a42fe9ed476c3adbfa3375f2f6d1571070d1e\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: diskcache, llama-cpp-python\n",
      "\n",
      "   ---------------------------------------- 0/2 [diskcache]\n",
      "   -------------------- ------------------- 1/2 [llama-cpp-python]\n",
      "   -------------------- ------------------- 1/2 [llama-cpp-python]\n",
      "   -------------------- ------------------- 1/2 [llama-cpp-python]\n",
      "   -------------------- ------------------- 1/2 [llama-cpp-python]\n",
      "   ---------------------------------------- 2/2 [llama-cpp-python]\n",
      "\n",
      "Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.14\n"
     ]
    }
   ],
   "source": [
    "! pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddedc571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\udayr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), 'MP-SENet-main', 'MP-SENet-main'))\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    SpeechT5Processor, \n",
    "    SpeechT5ForSpeechToText,\n",
    "    SpeechT5ForTextToSpeech,\n",
    "    SpeechT5HifiGan,\n",
    "    VitsModel, \n",
    "    VitsTokenizer\n",
    ")\n",
    "import bigvgan\n",
    "import librosa\n",
    "from models.model import MPNet\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a6d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SpeechPipeline:\n",
    "    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = 'cuda:0'\n",
    "        self.setup_models()\n",
    "        \n",
    "    def setup_models(self):\n",
    "        \"\"\"Initialize all models for the pipeline\"\"\"\n",
    "        print(\" Setting up models...\")\n",
    "        \n",
    "        # 1. Load MP-SENet for denoising\n",
    "        print(\"Loading MP-SENet for denoising...\")\n",
    "        self.load_mpsenet()\n",
    "        \n",
    "        # 2. Load SpeechT5 for ASR\n",
    "        print(\"Loading SpeechT5 for ASR...\")\n",
    "        self.asr_processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_asr\")\n",
    "        self.asr_model = SpeechT5ForSpeechToText.from_pretrained(\"microsoft/speecht5_asr\").to(self.device)\n",
    "        \n",
    "        # 3. Load BigVGAN + VITS for TTS\n",
    "        print(\"Loading TTS models (VITS + BigVGAN)...\")\n",
    "        self.tts_tokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\n",
    "        self.tts_model = VitsModel.from_pretrained(\"facebook/mms-tts-eng\").to(self.device).eval()\n",
    "        \n",
    "        # BigVGAN vocoder\n",
    "        self.vocoder = bigvgan.BigVGAN.from_pretrained(\n",
    "            \"nvidia/bigvgan_v2_44khz_128band_512x\",\n",
    "            use_cuda_kernel=False\n",
    "        )\n",
    "        self.vocoder.remove_weight_norm()\n",
    "        self.vocoder = self.vocoder.to(self.device).eval()\n",
    "        print(\"Loading DeepSeek R1 from local path...\")\n",
    "        from llama_cpp import Llama\n",
    "\n",
    "        self.deepseek = Llama(\n",
    "            model_path=r\"C:/Users/udayr/.lmstudio/models/lmstudio-community/DeepSeek-R1-Distill-Qwen-7B-GGUF/DeepSeek-R1-Distill-Qwen-7B-Q4_K_M.gguf\",\n",
    "            n_ctx=4096,\n",
    "            n_threads=8,  # adjust for your CPU\n",
    "            use_mlock=True\n",
    "        )\n",
    "        print(\" DeepSeek R1 loaded!\")\n",
    "\n",
    "        \n",
    "        print(\" All models loaded successfully!\")\n",
    "    \n",
    "    def load_mpsenet(self):\n",
    "        \"\"\"Load MP-SENet model\"\"\"\n",
    "        # Create a mock hyperparameter object for MP-SENet\n",
    "        class MPSENetConfig:\n",
    "            def __init__(self):\n",
    "                self.dense_channel = 64\n",
    "                self.n_fft = 400\n",
    "                self.beta = 1.0\n",
    "                self.sampling_rate = 16000\n",
    "        \n",
    "        config = MPSENetConfig()\n",
    "        self.mpsenet = MPNet(config, num_tsblocks=4).to(self.device)\n",
    "        \n",
    "        # Try to load pretrained weights if available\n",
    "        try:\n",
    "            checkpoint_path = \"MP-SENet-main/MP-SENet-main/best_ckpt/g_best_vb\"\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            self.mpsenet.load_state_dict(checkpoint['generator'])\n",
    "            print(\" Loaded pretrained MP-SENet weights\")\n",
    "        except:\n",
    "            print(\" Using random MP-SENet weights (pretrained not found)\")\n",
    "        \n",
    "        self.mpsenet.eval()\n",
    "    \n",
    "    def denoise_audio(self, audio_waveform, sample_rate=16000):\n",
    "        \"\"\"Denoise audio using MP-SENet\"\"\"\n",
    "        print(\" Denoising audio...\")\n",
    "        print(f\" Input audio shape: {audio_waveform.shape}\")\n",
    "        print(f\" Input audio range: [{np.min(audio_waveform):.4f}, {np.max(audio_waveform):.4f}]\")\n",
    "        print(f\" Input sample rate: {sample_rate}\")\n",
    "        \n",
    "        # Ensure mono and correct sample rate\n",
    "        if len(audio_waveform.shape) > 1:\n",
    "            audio_waveform = audio_waveform.mean(axis=0)\n",
    "         # Check if audio is too quiet\n",
    "        if np.max(np.abs(audio_waveform)) < 1e-6:\n",
    "            print(\"⚠️ Warning: Audio is very quiet or silent!\")\n",
    "        \n",
    "        # Resample if needed\n",
    "        if sample_rate != 16000:\n",
    "            audio_waveform = librosa.resample(audio_waveform, orig_sr=sample_rate, target_sr=16000)\n",
    "        print(f\"📊 Resampled audio shape: {audio_waveform.shape}\")\n",
    "        # Resample if needed\n",
    "        if sample_rate != 16000:\n",
    "            audio_waveform = librosa.resample(audio_waveform, orig_sr=sample_rate, target_sr=16000)\n",
    "        \n",
    "        # Convert to torch tensor\n",
    "        audio_tensor = torch.FloatTensor(audio_waveform).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        # Compute STFT\n",
    "        stft = torch.stft(\n",
    "            audio_tensor, \n",
    "            n_fft=400, \n",
    "            hop_length=100, \n",
    "            win_length=400, \n",
    "            return_complex=True\n",
    "        )\n",
    "        \n",
    "        magnitude = torch.abs(stft)\n",
    "        phase = torch.angle(stft)\n",
    "        print(f\" STFT magnitude shape: {magnitude.shape}\")\n",
    "        print(f\" STFT phase shape: {phase.shape}\")\n",
    "        # Apply MP-SENet\n",
    "        with torch.no_grad():\n",
    "            denoised_magnitude, denoised_phase, _ = self.mpsenet(magnitude, phase)\n",
    "        \n",
    "        # Reconstruct audio\n",
    "        denoised_stft = denoised_magnitude * torch.exp(1j * denoised_phase)\n",
    "        denoised_audio = torch.istft(\n",
    "            denoised_stft,\n",
    "            n_fft=400,\n",
    "            hop_length=100,\n",
    "            win_length=400\n",
    "        )\n",
    "        \n",
    "        return denoised_audio.squeeze().cpu().numpy()\n",
    "    \n",
    "    def speech_to_text(self, audio_waveform, sample_rate=16000):\n",
    "        \"\"\"Convert speech to text using SpeechT5 ASR\"\"\"\n",
    "        print(\" Converting speech to text...\")\n",
    "        print(f\" ASR input audio shape: {audio_waveform.shape}\")\n",
    "        print(f\" ASR input audio range: [{np.min(audio_waveform):.4f}, {np.max(audio_waveform):.4f}]\")\n",
    "        print(f\" ASR input sample rate: {sample_rate}\")\n",
    "        print(f\" Audio dtype: {audio_waveform.dtype}\")\n",
    "        print(f\" Audio is None: {audio_waveform is None}\")\n",
    "        print(f\" Audio length: {len(audio_waveform)}\")\n",
    "        \n",
    "        # Check if audio is empty or too quiet\n",
    "        if len(audio_waveform) == 0:\n",
    "            print(\" Error: Audio waveform is empty!\")\n",
    "            return \"Error: No audio data\"\n",
    "        \n",
    "        if np.max(np.abs(audio_waveform)) < 1e-6:\n",
    "            print(\" Warning: Audio is very quiet, may not transcribe well\")\n",
    "        \n",
    "        # Ensure audio is float32\n",
    "        if audio_waveform.dtype != np.float32:\n",
    "            audio_waveform = audio_waveform.astype(np.float32)\n",
    "        \n",
    "        # Ensure audio is normalized\n",
    "        max_val = np.max(np.abs(audio_waveform))\n",
    "        if max_val > 0:\n",
    "            audio_waveform = audio_waveform / max_val\n",
    "            print(f\" Normalized audio range: [{np.min(audio_waveform):.4f}, {np.max(audio_waveform):.4f}]\")\n",
    "        \n",
    "        try:\n",
    "            # Prepare input - explicitly pass audio parameter\n",
    "            print(\" Processing audio with ASR processor...\")\n",
    "            inputs = self.asr_processor(\n",
    "                audio=audio_waveform,  # Explicitly specify audio parameter\n",
    "                sampling_rate=sample_rate, \n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            # Move inputs to device\n",
    "            inputs = {k: v.to(self.device) if torch.is_tensor(v) else v for k, v in inputs.items()}\n",
    "            \n",
    "            print(f\" ASR processor inputs keys: {inputs.keys()}\")\n",
    "            for key, value in inputs.items():\n",
    "                if torch.is_tensor(value):\n",
    "                    print(f\" {key} shape: {value.shape}\")\n",
    "                    print(f\" {key} dtype: {value.dtype}\")\n",
    "                    print(f\" {key} device: {value.device}\")\n",
    "            \n",
    "            # Generate transcription\n",
    "            with torch.no_grad():\n",
    "                predicted_ids = self.asr_model.generate(**inputs)\n",
    "                transcription = self.asr_processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "            \n",
    "            print(f\" Transcription result: '{transcription}'\")\n",
    "            return transcription\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\" Error in speech_to_text: {e}\")\n",
    "            print(f\" Error type: {type(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return f\"Error: {str(e)}\"\n",
    "    def generate_response(self, prompt: str) -> str:\n",
    "        \"\"\"Use DeepSeek R1 to generate a response\"\"\"\n",
    "        print(\" Generating response with DeepSeek R1...\")\n",
    "        if \"Error:\" in prompt:\n",
    "            return \"I'm sorry, I couldn't understand what you said. Could you please try again?\"\n",
    "        \n",
    "        try:\n",
    "            output = self.deepseek(\n",
    "                prompt,\n",
    "                max_tokens=150,\n",
    "                stop=[\"</s>\"],\n",
    "                temperature=0.7\n",
    "            )\n",
    "            response = output[\"choices\"][0][\"text\"].strip()\n",
    "            print(f\" DeepSeek Response: {response}\")\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\" Error generating response: {e}\")\n",
    "    def text_to_speech(self, text):\n",
    "        \"\"\"Convert text to speech using VITS + BigVGAN\"\"\"\n",
    "        print(f\" Converting text to speech: '{text}'\")\n",
    "        \n",
    "        try:\n",
    "            # Tokenize text with VITS\n",
    "            inputs = self.tts_tokenizer(text, return_tensors=\"pt\").to(self.device)\n",
    "            \n",
    "            # Generate initial waveform with VITS\n",
    "            with torch.inference_mode():\n",
    "                vits_waveform = self.tts_model(**inputs).waveform\n",
    "                vits_audio = vits_waveform.squeeze().cpu().numpy()\n",
    "            \n",
    "            print(f\" VITS audio shape: {vits_audio.shape}\")\n",
    "            \n",
    "            # FIX 1: Use correct sampling rates\n",
    "            vits_sr = 22050  # ← CHANGE: VITS actually outputs at 22kHz, not 16kHz\n",
    "            bigvgan_sr = 22050  # ← CHANGE: Match BigVGAN to VITS rate\n",
    "            \n",
    "            # FIX 2: Don't resample if not needed\n",
    "            if vits_sr != bigvgan_sr:\n",
    "                vits_audio_resampled = librosa.resample(\n",
    "                    vits_audio, \n",
    "                    orig_sr=vits_sr, \n",
    "                    target_sr=bigvgan_sr\n",
    "                )\n",
    "            else:\n",
    "                vits_audio_resampled = vits_audio\n",
    "            speed_factor =1 \n",
    "            if speed_factor != 1.0:\n",
    "                print(f\"🐌 Slowing down audio by factor {speed_factor}\")\n",
    "                vits_audio_resampled = librosa.effects.time_stretch(\n",
    "                    vits_audio_resampled, \n",
    "                    rate=speed_factor\n",
    "                )\n",
    "                print(f\"📊 Slowed audio shape: {vits_audio_resampled.shape}\")\n",
    "            \n",
    "            # FIX 3: Use correct mel-spectrogram parameters for BigVGAN\n",
    "            mel_spectrogram = librosa.feature.melspectrogram(\n",
    "                y=vits_audio_resampled,\n",
    "                sr=bigvgan_sr,\n",
    "                n_mels=80,        # ← CHANGE: BigVGAN expects 80 mel bands, not 128\n",
    "                n_fft=1024,       # ← CHANGE: Smaller FFT size\n",
    "                hop_length=256,   # ← CHANGE: Smaller hop length\n",
    "                win_length=1024,  # ← CHANGE: Match n_fft\n",
    "                fmin=0,           # ← ADD: Minimum frequency\n",
    "                fmax=8000         # ← ADD: Maximum frequency (half of sample rate)\n",
    "            )\n",
    "            \n",
    "            # FIX 4: Convert to log scale and normalize\n",
    "            mel_spectrogram = np.log(mel_spectrogram + 1e-9)  # ← ADD: Log scale\n",
    "            mel_spectrogram = (mel_spectrogram - np.mean(mel_spectrogram)) / np.std(mel_spectrogram)  # ← ADD: Normalize\n",
    "            \n",
    "            # Convert to torch tensor and add batch dimension\n",
    "            mel_tensor = torch.FloatTensor(mel_spectrogram).unsqueeze(0).to(self.device)\n",
    "            \n",
    "            print(f\" Mel spectrogram shape: {mel_tensor.shape}\")\n",
    "            \n",
    "            # Generate high-quality audio with BigVGAN\n",
    "            with torch.inference_mode():\n",
    "                enhanced_audio = self.vocoder(mel_tensor)\n",
    "                enhanced_audio = enhanced_audio.squeeze().cpu().numpy()\n",
    "            \n",
    "            print(f\" Final audio shape: {enhanced_audio.shape}\")\n",
    "            return enhanced_audio, bigvgan_sr\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Error in text_to_speech: {e}\")\n",
    "            # Return VITS audio as fallback\n",
    "            return vits_audio, vits_sr  # ← CHANGE: Return correct sample rate\n",
    "    \n",
    "    def full_pipeline(self, audio_input, input_sample_rate=16000, response_text=None):\n",
    "        \"\"\"Complete pipeline: denoise → ASR → TTS\"\"\"\n",
    "        print(\" Starting full speech pipeline...\")\n",
    "        print(f\" Pipeline input audio shape: {audio_input.shape}\")\n",
    "        print(f\" Pipeline input sample rate: {input_sample_rate}\")\n",
    "        \n",
    "        # Step 1: Denoise\n",
    "        clean_audio = self.denoise_audio(audio_input, input_sample_rate)\n",
    "        \n",
    "        # Step 2: Speech to Text\n",
    "        transcription = self.speech_to_text(clean_audio, 16000)\n",
    "        print(f\" Final transcription: {transcription}\")\n",
    "        \n",
    "        # Step 3: Generate response\n",
    "        if response_text is None:\n",
    "            response_text = self.generate_response(transcription)\n",
    "        \n",
    "        # Step 4: Text to Speech\n",
    "        response_audio, sr = self.text_to_speech(response_text)\n",
    "        \n",
    "        return {\n",
    "            'transcription': transcription,\n",
    "            'response_text': response_text,\n",
    "            'response_audio': response_audio,\n",
    "            'sample_rate': sr,\n",
    "            'clean_audio': clean_audio\n",
    "        }\n",
    "    # 4. Load DeepSeek R1 (local GGUF model via llama.cpp bindings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb6ec378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting up models...\n",
      "Loading MP-SENet for denoising...\n",
      " Loaded pretrained MP-SENet weights\n",
      "Loading SpeechT5 for ASR...\n",
      " Error initializing pipeline: (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /api/models/microsoft/speecht5_asr/tree/main/additional_chat_templates?recursive=False&expand=False (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000231FC230E30>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 88d650a7-537e-459c-8a24-da47ed40fce2)')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "def main():\n",
    "     # Initialize pipeline\n",
    "    try:\n",
    "        pipeline = SpeechPipeline()\n",
    "    except Exception as e:\n",
    "        print(f\" Error initializing pipeline: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Record audio (example with sounddevice)\n",
    "    try:\n",
    "        import sounddevice as sd\n",
    "        print(\" Recording for 5 seconds...\")\n",
    "        duration = 10\n",
    "        sample_rate = 16000\n",
    "        \n",
    "        # Record audio\n",
    "        audio_input = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype=np.float32)\n",
    "        sd.wait()\n",
    "        audio_input = audio_input.flatten()\n",
    "        \n",
    "        print(f\" Recorded audio shape: {audio_input.shape}\")\n",
    "        print(f\" Recorded audio range: [{np.min(audio_input):.4f}, {np.max(audio_input):.4f}]\")\n",
    "        \n",
    "        # Check if recording worked\n",
    "        if np.max(np.abs(audio_input)) < 1e-6:\n",
    "            print(\" Warning: Very quiet recording, using synthetic audio for testing\")\n",
    "            # Generate some test audio\n",
    "            t = np.linspace(0, duration, int(duration * sample_rate))\n",
    "            audio_input = 0.1 * np.sin(2 * np.pi * 440 * t)  # 440Hz tone\n",
    "        \n",
    "        # Process through pipeline\n",
    "        result = pipeline.full_pipeline(audio_input, sample_rate)\n",
    "        \n",
    "        # Save output\n",
    "        sf.write(\"output_speech.wav\", result['response_audio'], result['sample_rate'])\n",
    "        print(f\"Output saved to output_speech.wav\")\n",
    "        print(f\" Transcription: {result['transcription']}\")\n",
    "        print(f\" Response: {result['response_text']}\")\n",
    "        \n",
    "        # Play result\n",
    "        sd.play(result['response_audio'], result['sample_rate'])\n",
    "        sd.wait()\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\" sounddevice not available, using dummy audio for testing\")\n",
    "        \n",
    "        # Use dummy audio for testing\n",
    "        dummy_audio = np.random.randn(16000 * 3) * 0.1  # 3 seconds of quiet noise\n",
    "        result = pipeline.full_pipeline(dummy_audio, 16000, \"Hello! This is a test response.\")\n",
    "        sf.write(\"test_output.wav\", result['response_audio'], result['sample_rate'])\n",
    "        print(\" Test output saved to test_output.wav\")\n",
    "        print(f\" Transcription: {result['transcription']}\")\n",
    "        print(f\" Response: {result['response_text']}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\" Error in main: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c4d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
